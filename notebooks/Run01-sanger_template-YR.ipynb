{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "\n",
    "from ceres_infer.session import workflow\n",
    "from ceres_infer.models import model_infer_iter_ens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get mitochondrial gene list\n",
    "import re\n",
    "with open('../data/gs16.txt','r') as f:\n",
    "    for lines in f:\n",
    "        lmito = re.findall(r'\\w+',lines)[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "params = {\n",
    "    # directories\n",
    "    'outdir_run': '../out/20.0929 feat/reg_rf_boruta/', # output dir for the run\n",
    "    'outdir_modtmp': '../out/20.0929 feat/reg_rf_boruta/model_perf/', # intermediate files for each model\n",
    "    'indir_dmdata_Q3': '../out/20.0925 proc_data/gene_effect/dm_data.pkl', # pickled preprocessed DepMap Q3 data\n",
    "    'indir_dmdata_Q4': '../out/20.0925 proc_data/gene_effect/dm_data_Q4.pkl', # pickled preprocessed DepMap Q3 data\n",
    "    'indir_dmdata_sanger': '../out/20.0925 proc_data/gene_effect/dm_data_sanger.pkl', # pickled preprocessed DepMap Q3 data\n",
    "    'indir_genesets': '../data/gene_sets/',\n",
    "    'indir_landmarks': None, # csv file of landmarks [default: None]\n",
    "\n",
    "    # notes\n",
    "    'session_notes': 'regression model, with random forest (iterative) and boruta feature selection; \\\n",
    "     run on selective dependent genes (CERES std > 0.25 and CERES range > 0.6)',\n",
    "\n",
    "    # data\n",
    "    'ext_data_name': 'sanger', # 'sanger' or 'Q4'\n",
    "    'opt_scale_data': True, # scale input data True/False\n",
    "    'opt_scale_data_types': '\\[(?:RNA-seq|CN)\\]', # data source types to scale; in regexp\n",
    "    'model_data_source': ['CERES','RNA-seq','CN','Mut','Lineage'],\n",
    "    'anlyz_set_topN': 10, # for analysis set how many of the top features to look at\n",
    "    'perm_null': 1000, # number of samples to get build the null distribution, for corr\n",
    "    'useGene_dependency': False, # whether to use CERES gene dependency (true) or gene effect (false)\n",
    "    'scope':'differential',# scope for which target genes to run on; list of gene names, or 'all', 'differential'\n",
    "\n",
    "    # model\n",
    "    'model_name': 'rf',\n",
    "    'model_params': {'n_estimators':1000,'max_depth':15,'min_samples_leaf':5,'max_features':'log2'},\n",
    "    'model_paramsgrid': {},\n",
    "    'model_pipeline': model_infer_iter_ens,\n",
    "    'pipeline_params': {},\n",
    "    \n",
    "    # pipeline\n",
    "    'parallelize': True, # parallelize workflow\n",
    "    'processes': 24, # number of cpu processes to use\n",
    "    \n",
    "    # analysis\n",
    "    'metric_eval': 'score_test',  # metric in model_results to evaluate, e.g. score_test, score_oob\n",
    "    'thresholds': {'score_rd10': 0.1,  # score of reduced model - threshold for filtering\n",
    "                   'recall_rd10': 0.95},  # recall of reduced model - threshold for filtering\n",
    "    'min_gs_size': 4 # minimum gene set size, to be derived\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Loading preprocessed data...\n",
      "INFO:root:Running model building and inference...\n",
      "INFO:root:Total number of processors available: 40\n",
      "INFO:root:Total number of processors to use: 24\n",
      "  0%|          | 0/583 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n",
      "Feature name/order across the datasets do not match. There are 91205 common feats, drop other feats\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/ceres_infer/data.py:366: UserWarning: gene GPR89A not found in shared CERES dataset...\n",
      "  warnings.warn('gene %s not found in shared CERES dataset...' % gene)\n",
      "  0%|          | 0/583 [10:35<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/storage/home/yur97/anaconda3/envs/cnp/lib/python3.7/multiprocessing/pool.py\", line 121, in worker\n    result = (True, func(*args, **kwds))\n  File \"/storage/home/yur97/anaconda3/envs/cnp/lib/python3.7/multiprocessing/pool.py\", line 44, in mapstar\n    return list(map(*args))\n  File \"../src/ceres_infer/session.py\", line 592, in infer_gene\n    [df_x,df_x_external] = qc_feats([df_x,df_x_external])\n  File \"../src/ceres_infer/data.py\", line 423, in qc_feats\n    if not np.all([len(dfs[0].columns) ==len(df.columns) for df in dfs]):\n  File \"../src/ceres_infer/data.py\", line 423, in <listcomp>\n    if not np.all([len(dfs[0].columns) ==len(df.columns) for df in dfs]):\nAttributeError: 'list' object has no attribute 'columns'\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-508bf860da71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpipeline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'load_processed_data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mwf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/storage/work/y/yur97/cnp_dev/src/ceres_infer/session.py\u001b[0m in \u001b[0;36mrun_pipe\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcompnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompnt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%s is not a component of the pipeline'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mcompnt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/storage/work/y/yur97/cnp_dev/src/ceres_infer/session.py\u001b[0m in \u001b[0;36minfer\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    148\u001b[0m                 \u001b[0mprocessesN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'processes'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m                 \u001b[0mchunksize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenes2analyz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mprocessesN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mdf_res\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimap_unordered\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenes2analyz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenes2analyz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m                     \u001b[0mmodel_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msort\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cnp/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/cnp/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    352\u001b[0m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m                 ))\n\u001b[0;32m--> 354\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    355\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m     def apply_async(self, func, args=(), kwds={}, callback=None,\n",
      "\u001b[0;32m~/anaconda3/envs/cnp/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    746\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 748\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    749\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m     \u001b[0m__next__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m                    \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# Run just the inference\n",
    "wf = workflow(params)\n",
    "pipeline = ['load_processed_data', 'infer']\n",
    "wf.create_pipe(pipeline)\n",
    "wf.run_pipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis, based on pre-existing inference\n",
    "wf = workflow(params)\n",
    "pipeline = ['load_processed_data', 'load_model_results', \n",
    "            'analyze', 'analyze_filtered', 'derive_genesets', 'run_Rscripts']\n",
    "wf.create_pipe(pipeline)\n",
    "wf.run_pipe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
