{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0860a4de2e062491567bac01bbbef181437a3458bd5f98fc4b8301e08ccc4fc55",
   "display_name": "Python 3.7.7 64-bit ('cnp': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## Double check on pie chart numbers.\n",
    "\n",
    "total: 583\n",
    "\n",
    "feat_summary_varEp: 583\n",
    "\n",
    "feat_summary (exclude all top10 univariate <= 0): 568\n",
    "\n",
    "filtered (by score_test and corr_test_recall)\n",
    "\n",
    "feat_summary_varEp: 529\n",
    "\n",
    "feat_summary (exclude all top10 univariate <= 0): 526"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from ceres_infer.utils import getFeatGene, getFeatSource\n",
    "from ceres_infer.analyses import generate_featSummary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../out/20.0216 feat/reg_rf_boruta/model_results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       model    feature target  score_train  score_test  score_oob  corr_test  \\\n",
       "0        all        all  FGFR1     0.629550    0.102785   0.096981   0.344408   \n",
       "1    topfeat    topfeat  FGFR1     0.728297    0.401316   0.462546   0.510498   \n",
       "2  top10feat  top10feat  FGFR1     0.707737    0.432236   0.487608   0.403751   \n",
       "\n",
       "   corr_test_recall  score_p19q4  corr_p19q4  corr_p19q4_recall  feat_id  \\\n",
       "0             0.998          NaN         NaN                NaN      NaN   \n",
       "1             0.999          NaN         NaN                NaN      NaN   \n",
       "2             1.000     0.505877    0.300472              0.986      NaN   \n",
       "\n",
       "   feat_idx  \n",
       "0       NaN  \n",
       "1       NaN  \n",
       "2       NaN  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>feature</th>\n      <th>target</th>\n      <th>score_train</th>\n      <th>score_test</th>\n      <th>score_oob</th>\n      <th>corr_test</th>\n      <th>corr_test_recall</th>\n      <th>score_p19q4</th>\n      <th>corr_p19q4</th>\n      <th>corr_p19q4_recall</th>\n      <th>feat_id</th>\n      <th>feat_idx</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>all</td>\n      <td>all</td>\n      <td>FGFR1</td>\n      <td>0.629550</td>\n      <td>0.102785</td>\n      <td>0.096981</td>\n      <td>0.344408</td>\n      <td>0.998</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>topfeat</td>\n      <td>topfeat</td>\n      <td>FGFR1</td>\n      <td>0.728297</td>\n      <td>0.401316</td>\n      <td>0.462546</td>\n      <td>0.510498</td>\n      <td>0.999</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>top10feat</td>\n      <td>top10feat</td>\n      <td>FGFR1</td>\n      <td>0.707737</td>\n      <td>0.432236</td>\n      <td>0.487608</td>\n      <td>0.403751</td>\n      <td>1.000</td>\n      <td>0.505877</td>\n      <td>0.300472</td>\n      <td>0.986</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_eval = 'score_test'\n",
    "def getVarExp(x):\n",
    "    # get variance explained\n",
    "    df = x.loc[x.model == 'univariate', ['feature', 'target', metric_eval]].copy()\n",
    "    df.columns = ['feature', 'target', 'score_ind']\n",
    "    df.score_ind = round(df.score_ind, 5)\n",
    "    df['score_rd'] = round(x.loc[x.model == 'top10feat', metric_eval].values[0], 5) if sum(\n",
    "        x.model == 'topfeat') > 0 else np.nan\n",
    "    df['score_full'] = round(x.loc[x.model == 'all', metric_eval].values[0], 5)\n",
    "    df['varExp_ofFull'] = round(df.score_ind / df.score_full, 5)\n",
    "    df['varExp_ofRd'] = round(df.score_ind / df.score_rd, 5)\n",
    "    df['feat_idx'] = list(range(1, df.shape[0] + 1))\n",
    "    return df\n",
    "\n",
    "varExp = df.groupby('target').apply(getVarExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "varExp.reset_index(inplace=True, drop=True)\n",
    "varExp['feat_gene'] = varExp['feature'].apply(getFeatGene, firstOnly=True)\n",
    "varExp['feat_source'] = varExp['feature'].apply(getFeatSource, firstOnly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "varExp.target.nunique() # original list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "568"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "varExp.loc[varExp.score_ind>0,:].target.nunique() # after filtering out target genes were R2s of all top 10 feat univariate models are negative\n",
    "# this is done in feat_summary = generate_featSummary(varExp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtering step\n",
    "# top 10 feat model with R2 > thresholds.score_rd10 (0.1)\n",
    "# top 10 feat model with recall > thresholds.recall_rd10 (0.95)\n",
    "\n",
    "df2 = df[df.model == 'top10feat']\n",
    "df2_filtered = df2[(df2.score_test > 0.1) & (df2.corr_test_recall > 0.95)]\n",
    "df2_filtered.target.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "varExp_filtered = varExp[varExp.target.isin(df2_filtered.target)]\n",
    "varExp_filtered.target.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "526"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "varExp_filtered.loc[varExp_filtered.score_ind>0,:].target.nunique() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}